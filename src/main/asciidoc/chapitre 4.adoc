

Chapitre 4

Mettre en place des tests unitaires
-----------------------------------

Le petit projet initial est maintenant de l'histoire ancienne. Sous
l'impulsion de contributeurs enthousiastes, de nombreuses
fonctionnalités sont venues l'enrichir. Il propose aujourd'hui une
multitude de services tous aussi indispensables les uns que les autres.
La diversité des contributions introduit cependant une nouvelle
difficulté : le projet est devenu quelque peu chaotique et relativement
hétérogène. À tel point qu'il devient délicat d'introduire une nouvelle
fonction sans risquer de "casser" quelque chose.

La solution, nous la connaissons déjà. Il est nécessaire de passer par
une phase de réingénierie (_refactoring_) pour mieux structurer notre
code et le simplifier, l’assouplir, le rendre extensible, adaptable,
bref : meilleur. Ce travail nécessite cependant de s'assurer que les
services rendus resteront les mêmes après ces modifications.

Aujourd'hui déjà, quelle que soit l'évolution que l'on désire apporter
au logiciel, fonctionnelle ou purement technique, nous sommes contraints
d'une façon ou d'une autre de vérifier les éventuelles erreurs et
incompatibilités que nous pourrions introduire involontairement. Nous
passons donc beaucoup de temps à tester l'application afin de voir si
elle continue de fonctionner "comme avant".

Tester ? Pour quoi faire ?
~~~~~~~~~~~~~~~~~~~~~~~~~~

Tester un logiciel est un travail répétitif, souvent ennuyeux, mais
pourtant indispensable. Nous devons évidemment vérifier que la toute
dernière évolution fonctionne comme prévu, ce qui est relativement
motivant. Nous devons également par la même occasion nous assurer que
tout le reste de l'application n'a pas perdu en stabilité. Un effet de
bord peut être dévastateur, et un bogue rapidement introduit. Et bien
souvent leur cause se cache dans une modification qui semble minime au
premier abord.

Une gestion de la qualité du logiciel doit prendre à bras-le-corps la
problématique des tests. Chaque version doit proposer une série de
vérifications à effectuer pour valider les nouveaux développements, mais
aussi inclure l'ensemble des tests identifiés pour les versions
précédentes, afin de s'assurer que l'application ne régresse pas. Il ne
faudrait pas casser quelque chose qui fonctionnait dans la version
précédente.

Une fonctionnalité qui disparaît ou se dégrade dans la version suivante,
c'est autant d'utilisateurs mécontents. Sans compter les nombreuses
heures perdues à identifier le problème et à lui trouver une solution
acceptable dans l'urgence : souvent un simple compromis avec la solution
"idéale" que l'on aimerait mettre en place mais qui nécessiterait trop
de travail ou introduirait de nouveaux risques.

Cependant, passer des tests a un coût, surtout si l'on accumule les
tests ajoutés par de nombreuses versions du logiciel. Reposer sur le
seul humain pour cette tâche, c'est s'exposer à de nombreux risques :

·     Le coût du passage des tests, considérant la main-d'œuvre employée
à plein-temps à cette tâche.

·     Le temps de réaction lorsqu'un problème a été introduit par une
modification. Plus tard on s'en rendra compte, plus la correction à
apporter sera délicate.

·     La rigueur du passage des tests, si l'on considère que l'être
humain se lasse vite de tâches répétitives et peu porteuses de
créativité.

Automatisons !
^^^^^^^^^^^^^^

Pour limiter ces risques, il existe une pratique simple et
particulièrement efficace : l'automatisation des tests ! Un mécanisme
automatique ne coûte pas grand-chose à l'exécution. En dehors de la
machine qu'il monopolise, il ne réclame pas d'augmentation ni de congés.
Il peut être très rapide et ne se lasse pas de ce qu'on lui demande de
faire. Même après des centaines de répétitions, il sera tout aussi
regardant sur le résultat qu'il est censé vérifier. Nous devons donc
voir les tests comme un traitement informatique intégré dans notre
projet. La création des tests, même si elle a un coût, est avant tout un
investissement qui nous prémunit des régressions dans le futur et
améliore l'évolutivité de notre logiciel en levant l'angoisse : "Je ne
touche pas au cas où je casserais quelque chose." Les tests automatisés
sont un véritable vecteur pour l'amélioration de la productivité des
équipes puisqu'ils leur permettent de se concentrer sur le logiciel en
toute quiétude même si une partie importante du code doit être
_refactorée_.

La solution la plus élémentaire pour mettre en place des tests
automatisés consiste à intégrer dans le code des fragments de tests, en
général sous forme d'une méthode main chargée de vérifier le
fonctionnement de la classe qui la définit, comme dans l'exemple du
Listing 4.1.

Listing 4.1 : Une méthode main de test

public class ListeDeCoursesReader \{

    public ListeDeCourses read( InputStream in ) \{ ... }

 

    /** Test automatique de la classe ListeDeCoursesReader */

    public static void main( String args[] ) \{

        ListeDeCoursesReader reader = new ListeDeCourseReader();

        ListeDeCourses lu = reader.read( new FileInputStream(
"./test.list" ) );

        if ( lu == null ) \{

            System.err.println( "FAILED : Erreur de lecture" ) ;

            System.exit( -1 ) ;

        }    

    }

}

Cette pratique est cependant très discutable. D'une part, elle nécessite
de passer par un lanceur qui va exécuter toutes les méthodes main des
tests, l'automatisation n'est donc pas complète. Ensuite, notre projet
va embarquer dans son code binaire le code de test, qui n'a pas grand
intérêt pour les utilisateurs. Si l'augmentation de la taille du fichier
JAR n'est pas en soi un problème bloquant, cela n'est pas
conceptuellement très satisfaisant.

Malgré ces quelques reproches, considérons tout de même cette option qui
a l'avantage d'être simple et a d'ailleurs été une pratique courante en
développement Java.

Pour améliorer la capacité de notre test à identifier un problème, nous
allons contrôler le contenu de l'objet ListeDeCourses lu lors de
l'exécution du test. Nous nous basons donc sur une comparaison entre un
objet ListeDeCourses ttendu et l'objet ListeDeCourses effectivement
construit lors de l'exécution du test. Pour ne pas devoir écrire la
comparaison entre ces deux objets (attendu _vs_ effectif), nous faisons
appel à la classe BeanComparator de la bibliothèque éprouvée
commons-beanutilslink:#_ftn19[[19]] qui fait ce travail pour nous en une
seule ligne de code, ce qui rend le test plus simple et plus lisible.
Inutile de réinventer la roue et de venir compliquer le code alors que
cette classe simplifie tellement la tâche et nous permet de nous
focaliser sur notre objectif : tester de manière automatique autant de
fonctionnalités que possible. Le Listing 4.2 montre cette évolution de
notre méthode de test.

Listing 4.2 : Utilisation d'une bibliothèque utilitaire dans le test

    /** Test automatique de la classe ListeDeCoursesReader */

    public static void main( String args[] ) \{

        ListeDeCoursesReader reader = new ListeDeCoursesReader();

        ListeDeCourses attendu = new ListeDeCourses( ... );

        ListeDeCourses lu = reader.read( new FileInputStream(
"./test.list" ) );

        if ( new BeanComparator().compare( attendu, lu ) != 0 ) \{

            System.err.println( "FAILED : Données lues incorrectes" ) ;

            System.exit( -1 ) ;

        }    

    }

Très fiers de notre mécanisme de test automatisé, nous lançons donc la
version fraîchement compilée de l'application sur notre serveur de test.
Et là, c'est la douche froide :

ClassNotFoundException org.apache.commons.beanutils.BeanComparator

Que s'est-il passé ? L'introduction d'une nouvelle bibliothèque pour
simplifier l'écriture du test a créé des imports dans le code, imports
qui ne peuvent être résolus sur le serveur de test car nous n'avons pas
ajouté la bibliothèque commons-beanutils à l'environnement de test. Cela
n'aurait aucun sens car, en dehors de ce test, elle n'est absolument pas
nécessaire !

Faut-il alors renoncer à utiliser des bibliothèques dans les tests et se
contenter du seul JDK ? Bien sûr que non ! Cela voudrait dire que nous
plaçons les tests au second plan et que nous nous interdisons d'en faire
quelque chose d'intelligent et de facile à écrire. De toute évidence, la
solution de la méthode main pour tester montre de graves limites.

Utiliser un framework de test
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Nous ne sommes pas les premiers à faire ce constat, et la réponse existe
depuis bien longtemps à travers des outils de test spécialisés pour
Java, dont le plus connu d'entre eux est jUnitlink:#_ftn20[[20]].

Ces outils reposent sur des principes simples :

·     Le test associé à une classe est écrit dans une classe Java
séparée implantant ce framework, qu'on nomme par convention du nom de la
classe testée avec le suffixe "Test".

·     Chaque test à réaliser est traduit par une méthode dédiée dans la
classe de test.

·     L'outillage propose des mécanismes d'initialisation et de
libération qui permettent de préparer les conditions d'exécution du test
et de fermer proprement les ressources après son exécution, même en cas
d'erreur.

·     L'outillage fournit des méthodes utilitaires pour les opérations
courantes de vérification du bon fonctionnement du logiciel.

·     L'outillage de test se charge d'identifier tous les tests à
exécuter et de les enchaîner, en fournissant au final un rapport complet
des éventuelles erreurs rencontrées.

Pour tester notre ListeDeCoursesReader avec jUnit, nous allons donc
écrire une classe ListeDeCoursesReaderTest, y créer une méthode
testLectureDeuxElements et y transférer notre code de test. Le
Listing 4.3 montre cette transformation de notre code

Listing 4.3 : Utilisation de jUnit

import static org.junit.Assert.*;

public class ListeDeCoursesReaderTest \{

 

    @Test

    public void lectureDeDeuxElements() \{

        ListeDeCoursesReader reader = new ListeDeCoursesReader();

        ListeDeCourses attendu = new ListeDeCourses( ... );

        ListeDeCourses lu = reader.read( new FileInputStream(
"./test.list" ) );

        assertEquals( 2, lu.size(), "liste lue de taille incorrecte" ) ;

        if ( new BeanComparator().compare( attendu, lu ) != 0 ) \{

            fail( "Données lues incorrectes" ) ;

        }    

    }

}

Cette nouvelle organisation nous permet de ne pas polluer le code de
notre projet, sans pour autant renoncer à nos tests automatisés. Elle
fournit un cadre simple pour l'écriture de ces tests et des méthodes
utilitaires pour nous aider à les écrire simplement. Elle nous propose
de prendre en charge l'exécution de nos tests, en fournissant _via_ une
interface graphique un compte rendu synthétique pointant immédiatement
les erreurs rencontrées. Ce rapport est en particulier parfaitement
intégré dans les environnements de développement comme Eclipse, NetBeans
ou IntelliJ Idea.

L'objectif de cet ouvrage n'est pas de détailler le fonctionnement de
jUnit. Nous ne pouvons donc que vous conseiller de consulter le site
junit.org et les nombreux ouvrages consacrés au sujet. Signalons
cependant que jUnit n'est pas le seul candidat pour l'écriture de tests
et qu’il partage ce terrain en particulier avec son challenger TestNG et
avec sa propre version "modernisée" jUnit4. Chacun a ses points forts,
aussi nous vous laissons choisir l'outil le plus approprié à vos besoins
et à vos habitudes de travail.

Les tests sous Maven
~~~~~~~~~~~~~~~~~~~~

Maven ne fait pas de choix entre ces trois outils de test. Plus
précisément, il choisit les trois plus tous ceux à venir qui pourraient
devenir les standards de demain. L'intégration des tests sous Maven
s'accommode de la bibliothèque de tests que vous déclarez comme
dépendances de votre projet et elle s'adapte en conséquence, en
téléchargeant les autres dépendances adéquates.

Nos tests sont désormais entièrement automatisés avec l'aide de notre
framework préféré. Reste à les intégrer dans la construction du projet.
En effet, l'intérêt de ces tests automatisés est… qu'ils sont
automatisés, donc contrôlables à tout moment pour le seul coût du temps
qu'ils nécessitent pour s'exécuter. La logique la plus élémentaire en
termes de qualité logicielle est que ces tests doivent être exécutés et
ne détecter aucune erreur avant que soit produit le binaire livrable à
nos utilisateurs.

Maven rejoint totalement cette logique et fait même des tests un élément
de premier plan du projet, au même niveau que le code de l'application
lui-même. Pour suivre la logique des outils de test comme jUnit ou
TestNG, Maven définit deux répertoires dans la structure de fichiers du
projet : src/main/java pour le livrable, src/test/java pour les tests.
La séparation entre classes du projet et classes de test qui l'outillent
est ainsi directement portée par l'emplacement physique des fichiers
sources.

Notre test jUnit ListeDeCoursesReaderTest est donc placé dans
l'arborescence src/test/java. Il ne nous reste qu'à lancer la commande
mvn test pour constater que Maven prend bien en charge la compilation et
l'exécution du test.

Cependant, notre ListeDeCoursesReaderTest comprend encore une faiblesse
notable : il fait appel à un fichier pour alimenter la classe testée.
Comment obtenir le chemin de ce fichier de manière totalement
indépendante de l'environnement ? Il est évidemment exclu de donner un
chemin en dur "C:/Utilisateurs/Nicolas/test/liste.list" qui serait assez
désastreux sur une machine non Windows ou sur un autre poste de travail
qui ne serait pas organisé de la même manière.

Nous avons donc utilisé un chemin relatif "test/liste.list", en
supposant implicitement que le test serait lancé depuis la racine du
projet où est placé ce fichier. Si cela fonctionne assez souvent, nous
sommes cependant un peu optimistes. C'est la raison d'être du répertoire
src/test/resources. Celui-ci permet de stocker toutes nos données de
test et d'y avoir accès à l'exécution du test _via_ le ClassPath. Le
Listing 4.4 montre l'évolution de notre code de test pour accéder à ce
fichier de cette manière. Tous les fichiers de données que nous
utiliserons pour nos tests seront placés sous src/test/resources. Ils
seront ainsi intégré au ClassPath de test, mais exclus du binaire final.
Ils seront également totalement intégrés au projet et enregistrés dans
notre gestionnaire de version.

Listing 4.4 : Accès aux fichiers de test en tant que ressources

    public void testLectureDeuxElements() \{

        ListeDeCoursesReader reader = new ListeDeCoursesReader();

        InputStream is = getClass().getResourceAsStream ( "test.list" );

        ListeDeCourses lu = reader.read( is );

...

Astuce

Ce mécanisme d'accès aux ressources est celui que nous vous recommandons
d'utiliser autant que possible. Cela s'applique lorsque vous manipulez
un type abstrait comme java.io.InputStream, java.net.URL, ou encore la
nouvelle API java.nio.file de Java7.

Si vous devez expressément utiliser un type java.io.File, ne supposez
pas que le répertoire courant est forcément la racine du projet (nous
verrons au Chapitre 7 que ce n'est pas toujours le cas). Maven fournit
la variable système basedir qui pointe à la racine du projet. Utilisez
donc :

File basedir = new File( System.getProperty( "basedir", "" )  )

                   .getAbsoluteFile();

File monFichier = new File( basedir, "chemin/relatif" ) ;

Le scope "test"
^^^^^^^^^^^^^^^

Nous avons vu que la bibliothèque commons-beanutils nous a joué un
mauvais tour. Bien pratique pour simplifier l'écriture de notre test,
elle venait perturber notre application. Maintenant que le test possède
sa propre classe dédiée, ce problème est en principe résolu. Cependant,
les utilisateurs d'IDE font confiance à leur environnement pour gérer
les imports et peuvent se faire piéger à nouveau. Il est si facile
d'ajouter un import en saisissant juste le début du nom d'une classe
qu'il n'est pas rare de terminer son travail avec quelques imports
inutiles. L'IDE peut également faire le ménage pour nous, mais qu’il
laisse passer une coquille par mégarde n'est pas exclu.

Contrairement à un projet dans les IDE courants, un projet Maven a deux
visages bien définis : la branche principale (src/main), portant le code
de l'application et les dépendances qui lui sont associées dans le POM,
et la branche test (src/test), portant l'outillage de contrôle ainsi que
ses dépendances dédiées. En effet, une dépendance déclarée dans le POM
porte une indication de scope, qui permet à Maven de savoir quand telle
ou telle bibliothèque doit être utilisée par les outils de compilation.
Lorsque le scope porte la valeur test, il est exclu de l'application et
ne sera utilisé que pour la compilation et l'exécution des tests.

    <dependency>

      <groupId>junit</groupId>

      <artifactId>junit</artifactId>

      <version>4.8.2</version>

      <scope>test</scope>

    </dependency>

Si l'assistance de l'IDE nous a fait intégrer par erreur des classes
normalement dédiées à notre outillage de test, la compilation par Maven
échouera en signalant immédiatement le problème. Nous pouvons donc faire
appel à tous les utilitaires possibles et imaginables qui nous aideront
à écrire nos tests de manière plus efficace et sans risquer de polluer
l'application.

Le choix d'outils de tests est parfois plus délicat que le choix de
l'infrastructure de notre logiciel. Pour être pertinents et bien couvrir
les besoins, les tests doivent rester simples et performants et peuvent
utiliser les ressources de nombreuses bibliothèques. La gestion de
dépendances transitive de Maven nous ouvre les portes d'outils de test
et de simulation très avancés, avec une simplicité de mise en œuvre
déconcertante.

Le développement piloté par les tests
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Les tests automatisés que nous venons d'ajouter à notre projet nous
offrent un garde-fou intéressant. À de nombreuses reprises, ils nous
signalent qu'une "petite modification" s'avère bien plus significative
que ce que nous avions pensé.

image:illustrations/MangaVincentM.png[float="left"]

Au cours d'une discussion sur les nouvelles idées que nous avons eues
pour notre projet, Vincent propose de changer le format du fichier dans
lequel nous stockons la liste de courses. Cette modification permettra
de stocker des données complémentaires, dont je vous laisse le soin
d'imaginer l'utilité.

Nos tests existants permettront de vérifier que ce nouveau format ne
perturbe pas le code existant, mais Vincent va plus loin. Avant même que
nous n’ayons déterminé comment nous allions lire ces nouvelles données
depuis le fichier, il commence à écrire une nouvelle méthode de test
vérifiant que les informations supplémentaires ont été correctement
lues. Aurait-il "oublié" que, pour que le logiciel fonctionne, il faut à
un moment ou un autre réaliser son code ?

Une fois son test écrit, Vincent le lance et ne semble même pas vexé de
voir son écran afficher dans un rouge sang le résultat assez
prévisible :

FAILURE

java.lang.NullPointerException

Vincent est tout simplement un adepte du développement piloté par les
tests (Test Driven Development ou _Test First_). Plutôt que de tester
son code, il préfère écrire des tests qui décrivent précisément ses
attentes, puis écrire le code qui sera capable de faire passer ses tests
au vert. La différence est étonnamment efficace en termes de
structuration du logiciel. Plutôt que d'être guidé par des contraintes
techniques ou par des considérations de pur informaticien, chaque
élément du logiciel n'existe que parce que la bonne exécution d'un test
nécessitait son existence. Comme chaque test est guidé par un besoin,
écrit avant même que l'on n’ait commencé à se torturer l'esprit avec la
réalisation, le code répond de manière simple et juste aux besoins.

La sur-ingénierie est une dérive courante de l'informatique où des
composants deviennent inutilement complexes au regard de la
fonctionnalité à rendre, simplement pour répondre à des considérations
purement techniques qui n'apportent rien à l'utilisateur.

Vincent a donc écrit d'abord une méthode de test simple, focalisée sur
sa nouvelle idée et uniquement guidée par ce qu'il attend du logiciel et
non pas par l'idée qu'il a derrière la tête concernant les technologies
qui vont l'aider ou le code qu'il va mettre en œuvre. Après cette phase
préparatoire qu'on pourrait qualifier dans un vocabulaire plus
traditionnel d'expression de besoin, Vincent est content de voir son
test échouer : le test est valide et vérifie bien quelque chose que
l'application ne fournit pas encore. Ne riez pas, trop souvent des tests
ne font qu'effleurer l'application et n'échouent pas si l'on supprime le
code censé être testé !

Vincent commence ensuite la réalisation. Après quelques lignes de code,
le test lancé à nouveau échoue encore mais sur un cas d'erreur moins
abrupt :

FAILURE

Assertion Failed : actual 1, expected 2

Le code commence donc à se mettre en place mais ne répond pas encore aux
attentes. Quelques minutes plus tard et après que les corrections qui
s'imposent ont été apportées, le test passe enfin au vert.

Cette façon de travailler est un moyen très puissant de structurer ses
développements en fonction du résultat à atteindre et non en répondant à
nos pulsions d'informaticiens avides de code. Une règle de base du
développement piloté par les tests est qu'aucun code ne doit être écrit
s'il n'est pas rendu indispensable par un test. Autrement dit, d'une
part, du code non testé ne devrait pas exister, et d'autre part, du code
qui n'est pas guidé par un besoin fonctionnel n'a rien à faire dans un
logiciel intelligemment construit.

La réalisation du code qui répond à son test lui a permis d'identifier
de nouvelles portions de code très proches d'autres déjà existantes. Il
aimerait bien les regrouper dans des méthodes communes. La duplication
de code est l'ennemi d'un logiciel évolutif et fiable, aussi Vincent
applique le second commandement du développement piloté par les tests :
DRY (Don't Repeat Yourself – "Tu ne te répéteras pas").

Armé de ses tests, tous focalisés sur des aspects unitaires ou
fonctionnels de l'application, il peut faire toutes les opérations de
réingénierie qui lui semblent nécessaires pour arriver à un bon niveau
de structuration. Chaque modification apportée est contrôlée par les
tests existants qui assurent ainsi que le logiciel reste
fonctionnellement équivalent. L'outillage de test en place permet à
présent de se focaliser sur des aspects purement techniques, pour ne pas
dire esthétiques, concernant l'organisation de notre code. Niveau
d'abstraction, évolutivité, lisibilité. Chaque modification que nous lui
apporterons afin d'en améliorer la qualité pourra être validée d'un
point de vue des fonctions rendues par l'application : nos tests doivent
tous rester au vert. Certaines modifications lourdes et pourtant
importantes n'auraient jamais été réalisées en confiance sans cette
garantie.

Figure 04-01

Développement piloté par les tests.

Le développement piloté par les tests est une pratique préconisée par de
nombreuses méthodes agileslink:#_ftn21[[21]]. Sa mise en œuvre efficace
nécessite une culture du test automatisé pour être réellement efficace.
Maven participe à cette démarche par la place qu'il donne au test dans
le cycle de vie du projet. Les tests vus par Maven sont des éléments de
premier plan du projet.

Pas de JAR sans tests réussis
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Le passage des tests par Maven fait partie des phases standard de
construction du projet. Maven les place au cœur de la gestion de la
qualité et fait le choix de bloquer la construction du projet si un test
échoue. Comme ces tests sont exécutés avant que la phase de packaging
qui construit le JAR ne soit exécutée, Maven interdit donc de construire
un livrable qui ne passe pas avec succès tous les tests définis par le
projet. C'est une interprétation rigoureuse des principes de qualité
logicielle mais qui évite d'utiliser par mégarde un JAR fraîchement
compilé et de découvrir de manière détournée et coûteuse un bogue qui
est déjà contrôlé par un test unitaire.

image:illustrations/MangaFabrice.png[float="left"]

Interdire la construction du JAR, n'est-ce pas un peu abrupt comme prise
de position ? C'est en tout cas l'avis de Fabrice, qui tue le temps dans
le TGV en testant rapidement quelques nouvelles idées et qui ne parvient
pas à lancer l'application. Ses modifications, réalisées en mode
"exploratoire", ne visent qu'à tester un nouveau concept et certainement
pas à obtenir un résultat stable et irréprochable.

Maven met certes les concepts de qualité logicielle au premier plan mais
ne manque cependant pas de pragmatisme. Il existe une option qui permet
de ne pas passer les tests lors de la construction du projet, et donc de
passer outre cette règle parfois trop stricte. Cette option, ajoutée sur
la ligne de commande, est –DskipTests. C'est une option à double
tranchant, soyez-en bien conscient. Elle peut être indispensable, comme
le pense Fabrice qui peut ainsi vérifier la pertinence de son idée,
auquel cas il pourra la présenter à son client à l'arrivée de son voyage
d'affaires. C'est une option dangereuse si elle est trop utilisée et que
nos tests automatisés ne soient plus exécutés.

Réutiliser notre outillage de test
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Au fur et à mesure de l'écriture des tests, nous avons dû développer des
classes utilitaires qui n'ont de sens que dans le cadre des tests : code
bouchon et simulateurs, mécanisme de contrôle et autres constituent un
outillage complet dédié à notre code afin que nous soyons en mesure de
le tester convenablement.

image:illustrations/MangaLukas.png[float="left"]

En marge de notre projet, Lukas se lance dans un autre projet
expérimental pour proposer une version sur téléphone mobile de notre
application – une cible de choix qu'il ne faut pas négliger !

Lukas est rapidement confronté à un problème simple : dans son
environnement de développement, il dispose des deux projets et peut donc
coder les tests de son projet noubliepaslalistedescourses-on-android en
réutilisant nos utilitaires de test. Cet outillage lui simplifie
grandement la tâche et lui permet d'écrire des tests pertinents et
lisibles en un temps record. Seulement, lorsqu'il tente de construire
son projet avec Maven, la compilation de ses tests échoue
systématiquement : nos utilitaires ne sont pas vus par le compilateur.

Cette situation en apparence paradoxale est simple à expliquer. La
majorité des environnements de développement intégrés ne différencient
pas – contrairement à Maven – les bibliothèques utilisées pour écrire le
code et celles associées aux tests. En référençant le projet
noubliepaslalistedescourses, l'environnement donne accès à toutes ses
classes et dépendances, sans distinction. Maven par contre s'appuie sur
le JAR qui a été construit par chaque projet, et sur lui seul. Nos
utilitaires de test ne sont accessibles qu'au cours de la construction
du projet qui les définit et pas en dehors. Le projet de Lukas ne peut
donc exploiter que les classes qui sont destinées à l'inclusion dans le
JAR final, et pas la panoplie de tests qui les accompagne.

Copier-coller ces classes est évidemment hors de question, et nous ne
pouvons demander à Lukas de réécrire entièrement ses tests sans ce code
de support qui lui a fait gagner tant de temps. La solution, Maven la
fournit _via_ le plugin jar, responsable de la construction de notre
archive.

Comme nous l'avons vu, le plugin jar est attaché par défaut au cycle de
construction du projet lors de la phase package et sa tâche jar
construit l'archive – rien de très surprenant. Ce plugin définit
d'autres tâches, en particulier une qui va nous sauver la mise :
test-jar. Celle-ci permet de construire en parallèle du JAR du projet un
second JAR, contenant cette fois les classes et ressources de test. Le
Listing 4.5 montre la configuration associée au plugin jar pour obtenir
ce résultat. Le fonctionnement par défaut suffit à notre besoin, aussi
l'ajout de ce traitement ne nécessite aucun élément de configuration
particulier.

Listing 4.5 : Construction d'un test-jar en même temps que l'archive
java du projet

      <plugin>

        <groupId>org.apache.maven.plugins</groupId>

        <artifactId>maven-jar-plugin</artifactId>

        <version>2.3.1</version>

        <executions>

          <execution>

            <goals>

              <goal>test-jar</goal>

            </goals>

            <inherited>false</inherited>

          </execution>

        </executions>       

      </plugin>

Cette seconde archive partage les métadonnées du projet (le POM). Il ne
s'agit pas d'un second projet Maven contenant nos tests, mais bien d'un
aspect secondaire de notre unique projet dont Maven se propose de gérer
la construction. La différenciation entre l'artefact principal du projet
et des résultats secondaires de ce type s’appuie sur un suffixe ajouté
au nom de l'artefact, ce que dans le vocabulaire Maven on nomme un
classifier. La tâche test-jar va construire un artefact nommé
noubliepaslalistedescourses-1.0-SNAPSHOT-tests.jar.

Maven peut être configuré pour produire plus d'un artefact lors de la
construction du projet et le classifier permet de différencier les
artefacts secondaires du principal résultat de la construction. Il est
ainsi possible de construire non seulement le JAR du projet, mais aussi
le JAR de ses tests, le JAR de son code source ou le JAR de sa
documentation JavaDoc. Chacun de ses artefacts secondaires pourra être
référencé comme une dépendance en ajoutant l'information de classifier
adéquate, comme le montre le Listing 4.6 qui présente le POM du projet
de Lukas.

Listing 4.6 : Utilisation d'une dépendance exploitant la notion de
classifier

<project>

  <modelVersion>4.0.0</modelVersion>

  <groupId>fr.noubliepaslalistedescourses</groupId>

  <artifactId>noubliepaslalistedescourses-on-android</artifactId>

  <version>1.0-SNAPSHOT</version>

  <description>

    Projet annexe de noubliepaslalistedescourses pour un client sur
téléphone mobile Androïd

  </description>

 

  <dependencies>

    <dependency>

      <groupId>fr.noubliepaslalistedescourses</groupId>

      <artifactId>noubliepaslalistedescourses</artifactId>

      <version>1.0-SNAPSHOT</version>

    </dependency>

 

    <dependency>

      <groupId>fr.noubliepaslalistedescourses</groupId>

      <artifactId>noubliepaslalistedescourses</artifactId>

      <version>1.0-SNAPSHOT</version>

      <classifier>tests</classifier>

      <type>test-jar</type>

      <scope>test</scope>

    </dependency>

   

  </dependencies>

</project>

L'intégration continue
^^^^^^^^^^^^^^^^^^^^^^

Nous l'avons vu, nos tests automatisés prennent toute leur valeur
lorsqu'ils sont exécutés régulièrement. Chaque développeur peut compter
sur eux pour vérifier qu'il n'a pas (ou au moins, pas trop, en fonction
de la qualité des tests) détraqué l'application avec ses dernières
modifications. Cela peut même l'aider à identifier les points à
reprendre sur des parties de l'application qu'il ne connaît pas bien ou
à structurer ses propres développements.

Une autre utilisation des tests est de rendre leur passage systématique
sur une machine dédiée, afin de détecter le plus vite possible une
erreur introduite par un développeur qui n'aurait pas identifié le
problème par lui-même. Il ne s'agit pas du tout de rechercher le mouton
noir qui introduit des bogues et ne vérifie rien sur son environnement.
Il n'est pas rare de créer des instabilités parce qu'on a oublié de
diffuser un fichier sur le gestionnaire de version ou parce qu'un
fragment de code dépend de l'encodage des fichiers sur le système, d'un
chemin particulier, ou de la version du JDK utilisée.

Cette machine qui va incessamment analyser notre projet en exécutant
tous les tests aura l'avantage énorme sur un contrôleur humain de n'être
limitée que par sa rapidité d'exécution pour signaler les problèmes.
À la moindre faute, elle pourra se fonder sur la liste des dernières
modifications pour signaler aux personnes concernées le problème
identifié. Venant d'un automate plutôt que d'un collègue, ce genre de
reproche est plus facile à accepter.

Ce contrôle automatisé et incessant fait partie (mais n'est qu'un
élément) de l'intégration continue, une pratique introduite par les
méthodes de développement agiles. C'est un outil puissant et facile à
mettre en place que nous ne pouvons que vous recommander. Même si, dans
un premier temps, vous ne l'utilisez que pour contrôler la bonne
exécution des tests et identifier au plus tôt les défaillances de vos
collaborateurs et les faiblesses de votre application, vous constaterez
rapidement ses bénéfices et les bonnes pratiques que vous pouvez en
tirer.

Le serveur qui va exécuter nos tests peut se baser sur l'un des nombreux
outils disponibles. Nous citerons Continuum et Hudson, mais cette liste
est loin d'être exhaustive.

Continuum
^^^^^^^^^

Continuum a été développé par la communauté Maven, avec bien sûr pour
objectif de prendre en charge de manière aussi intégrée que possible la
structure des projets Maven et les relations de dépendance qu'ils
peuvent entretenir. Il ne se limite cependant pas à ce type de projets
et peut tout aussi bien accueillir vos projets Ant ou outillés par des
scripts.

Son point fort est son excellente intégration des projets Maven. Sur
détection d'un changement dans le gestionnaire de code source, Continuum
va ainsi construire uniquement le projet impacté puis enchaîner avec
tous les autres projets qui l'utilisent et pourraient être impactés de
manière indirecte par ce changement.

Son premier point faible est son interface web qui ne bénéficie pas des
raffinements auxquels nous ont habitués les applications web modernes.
Un peu trop de configuration et de changement de page sont nécessaires
pour l'exploiter.

Son second et principal point faible est l'absence de mécanismes
d'extension permettant des contributions et des adaptations de l'outil à
des contextes projets spécifiques, sans devoir entrer dans les rouages
très techniques de l'outil. Par ailleurs, la lenteur de son cycle de
développement, qui ne propose une nouvelle version qu'après plusieurs
mois, réduit sa capacité à proposer rapidement des évolutions à ses
utilisateurs.

Figure 04-02

Continuum en train de surveiller les projets de Maven2.

Jenkins
^^^^^^^

Créé par Kohsuke Kawaguchi, employé de SUN, pendant son temps libre,
Jenkins est rapidement devenu un outil incontournable. Son cycle de
développement est extrêmement bref, au point qu'il est difficile de
choisir une version, la suivante pouvant apparaître dans les jours ou
les heures qui suivent. Cette très forte réactivité permet cependant
d'apporter rapidement les corrections qui s'imposent et de proposer des
fonctionnalités nouvelles par petites touches.

Jenkins n'est pas dédié à Maven et peut tout aussi bien accueillir des
projets Ant ou simplement basés sur des scripts. Le support de Maven,
bien qu'arrivé tardivement et longtemps considéré comme expérimental,
est cependant d'un bon niveau et parfaitement fonctionnel.

Les points forts de Jenkins sont la qualité de son interface web et
l'extrême simplicité de son installation. Son principal point faible (en
progrès constant) est l'intégration en constante amélioration mais
toujours perfectible des projets Maven, en particulier ceux répartis en
plusieurs modules (voir Chapitre 6).

Le point décisif qui fait de Jenkins un concurrent de choix, c'est sa
réactivité de développement. Avec une nouvelle version chaque semaine et
une armée de contributeurs sur son écosystème de plugins, Jenkins est un
logiciel extrêmement réactif et porteur de nombreuses innovations.

Figure 04-03

 

Jenkins, en train de surveiller sa propre construction, respectant
l'adage anglo-saxon « eat your own dog food » (« mange ta propre
nourriture pour chien »)

Hudson
^^^^^^

Hudson est le cousin de Jenkins. Suite au rachat de SUN par Oracle, ce
dernier a fait valoir ses droits sur le nom « hudson », marque déposée
et nom historique du projet. Voulant imposer ses règles à la communauté
des développeurs, Oracle a provoqué un divorce,  qualifiée de fork dans
le vocabulaire de l'open-source. Ainsi est né Jenkins d'une part,
continuité naturelle du projet, et Oracle Hudson® de l'autre, développé
et supporté par Oracle et ses partenaires.

Techniquement parlant, les deux projets sont relativement identiques à
l'heure ou nous écrivons ces lignes, mais ne suivront pas les mêmes
choix techniques ou organisationnels à l'avenir.

Figure 04-04

Husdon, lui aussi en train de surveiller la construction de Maven2, dans
la forge Sonatype, partenaire d'Oracle.

Lequel choisir ?
^^^^^^^^^^^^^^^^

Le choix de votre serveur d'intégration continue va dépendre de nombreux
critères. Techniquement parlant, il faut qu'il soit adapté à vos
environnements, qu'il sache communiquer avec votre gestionnaire de
versions et éventuellement à votre outil de suivi de bogues. Il faudra
aussi qu'il puisse facilement remonter de l'information aux
développeurs, par mail, messagerie instantanée, plugin dans
l'environnement de développement ou autre. Dans tous les cas, il faudra
vérifier que la compatibilité est au rendez-vous.

Ce ne sont pas les seuls critères à retenir. Nous n'avons vu ici qu'une
utilisation très superficielle de l'intégration continue, qui se
contente de compiler et de tester régulièrement notre projet pour
signaler les erreurs. La pratique d'intégration continue va très
au-delà, comme nous le verrons au chapitre suivant. En fonction de votre
utilisation, certaines fonctionnalités vous sembleront indispensables et
d'autres, inutiles. Les possibilités d'extension et de configuration de
ces serveurs sont nombreuses et répondent à des usages et à des règles
de fonctionnement très variés.

Quelques pistes pour vous guider :

·      Que devra surveiller l'intégration continue ? Votre gestionnaire
de code source est-il supporté ?

·      Avez-vous autre chose que des builds Maven à lui faire supporter
? Avez vous des développements sous Ant, Ruby on Rails, Python, Grails,
… qui pourraient bénéficier de cette initiative ?

·      Qu'attendez-vous de l'intégration continue ? Quels processus de
contrôle devra t-elle porter ? Métriques qualité, tests fonctionnels ou
de performance, déploiement d'une version de démonstration, publication
des résultats ?

·      Comment doit-elle interagir avec vous ? IHM web seule et
diffusion de mails, notification par messagerie instantanée, plugin dans
votre IDE ?

·      Quel support êtes vous prêt à fournir pour votre service
d'intégration continue ? Mises à jour régulières, phase de qualification
et/ou support commercial ?

Conclusion
~~~~~~~~~~

Les tests unitaires sont des acteurs de premier plan pour introduire la
qualité logicielle dans le cycle de développement du projet. Maven les
considère comme tels et son fonctionnement même participe très
activement à la promotion de cette pratique.

L'intégration de tests dans un projet nécessite un changement de
pratiques et l'appropriation de nouveaux outils, elle n'est donc ni
instantanée, ni totalement gratuite. Le "retour sur investissement" est
cependant sans commune mesure une fois les bonnes habitudes en place. Un
projet outillé par des tests rassure tout le monde sur son niveau de
qualité et sa stabilité dans le temps. Livrer un logiciel dont tous les
tests sont au vert est autrement plus rassurant pour l'équipe que
d'appliquer les derniers correctifs en espérant ne pas avoir introduit
d'erreur à quelques heures de la livraison.